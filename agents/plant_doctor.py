import logging
from typing import TypedDict, Dict, Any, Optional, List
from langgraph.graph import StateGraph, END
from langchain_core.messages import HumanMessage, SystemMessage
from langchain_community.chat_models import ChatOllama

# --- IMPORTATION DES OUTILS M√âTIERS ---
from tools.health.base_health import HealthDoctorTool

logger = logging.getLogger("Agent.HealthSahel")

# ==============================================================================
# 1. D√âFINITION DE L'√âTAT (STATE)
# ==============================================================================
class AgentState(TypedDict):
    user_query: str
    culture_config: Dict[str, Any]
    diagnosis_raw: Optional[Dict[str, Any]]
    technical_advice_text: str
    final_response: str
    status: str  # 'START', 'FOUND', 'UNKNOWN', 'ERROR'

# ==============================================================================
# 2. L'AGENT DE SANT√â V√âG√âTALE
# ==============================================================================
class PlantHealthDoctor:
    def __init__(self, ollama_host: str = "http://localhost:11434", llm_client=None, model_name: str = "mistral"):
        self.doctor = HealthDoctorTool() 
        self.model_name = model_name
        self.llm = llm_client if llm_client else self._initialize_llm(model_name, ollama_host)

    def _initialize_llm(self, model_name, ollama_host):
        try:
            return ChatOllama(model=model_name, base_url=ollama_host, temperature=0.1)
        except Exception as e:
            logger.error(f"‚ùå √âchec connexion LLM: {e}")
            return None

    def _identify_symptoms_semantically(self, user_text: str) -> str:
        """D√©tecte les mots-cl√©s techniques √† partir du langage naturel."""
        if not self.llm: 
            return user_text
        
        prompt = (
            "Tu es un expert en phytopathologie sah√©lienne.\n"
            "Analyse les sympt√¥mes d√©crits par l'agriculteur et extrais les termes techniques.\n"
            "Exemple : 'fleurs violettes' -> STRIGA WONGO.\n"
            f"Description : '{user_text}'\n"
            "R√©ponds UNIQUEMENT avec les mots-cl√©s extraits, s√©par√©s par des virgules."
        )
        try:
            resp = self.llm.invoke([SystemMessage(content=prompt)])
            return f"{user_text}, {resp.content.upper()}"
        except Exception:
            return user_text

    # --- N≈íUD 1 : ANALYSE ---
    def analyze_node(self, state: AgentState) -> Dict[str, Any]:
        logger.info("--- NODE: ANALYSE ---")
        config = state.get("culture_config", {})
        crop = config.get("crop_name", "Culture inconnue")
        query = state.get("user_query", "")
        
        # 1. Identification s√©mantique
        enhanced_query = self._identify_symptoms_semantically(query)

        # 2. Diagnostic via l'outil m√©tier
        diag = self.doctor.diagnose_and_prescribe(crop=crop, user_obs=enhanced_query)

        if diag.get("status") == "Trouv√©" or "diagnostique" in diag:
            # Extraction dynamique du tutoriel (ex: neem ou piment selon le diagnostic)
            target_bio = diag.get("target_pest", "neem")
            prep_aid = self.doctor.get_biopesticide_tutorial(target_bio)
            
            report = (
                f"üéØ PATHOLOGIE : {diag.get('diagnostique')}\n"
                f"‚ö†Ô∏è RISQUE : {diag.get('niveau_alerte')}\n"
                f"üåø SOLUTION BIO : {diag.get('prescription_bio')}\n"
                f"üìñ M√âTHODE : {prep_aid}\n"
                f"üß™ CHIMIE (Dernier recours) : {diag.get('conseil_chimique')}\n"
                f"üõ°Ô∏è PR√âVENTION : {diag.get('prevention')}"
            )
            return {
                "diagnosis_raw": diag,
                "technical_advice_text": report,
                "status": "FOUND"
            }
        
        return {
            "technical_advice_text": "D√©sol√©, je n'ai pas pu identifier la maladie. Veuillez consulter un agent de terrain.",
            "status": "UNKNOWN"
        }

    # --- N≈íUD 2 : FORMATAGE ---
    def format_node(self, state: AgentState) -> Dict[str, Any]:
        logger.info("--- NODE: FORMATAGE ---")
        if not self.llm or state["status"] != "FOUND":
            return {"final_response": state["technical_advice_text"]}

        system_prompt = (
            "Tu es le Gu√©risseur des Plantes d'AgriConnect.\n"
            "TON : Bienveillant, expert, protecteur. Utilise des listes √† puces.\n"
            "R√àGLE D'OR : Priorit√© absolue aux rem√®des naturels (Bio)."
        )

        try:
            msg = self.llm.invoke([
                SystemMessage(content=system_prompt),
                HumanMessage(content=f"Transforme ce rapport en conseil amical :\n{state['technical_advice_text']}")
            ])
            return {"final_response": msg.content}
        except Exception:
            return {"final_response": state["technical_advice_text"]}

    # --- CONSTRUCTION DU GRAPH ---
    def get_graph(self):
        workflow = StateGraph(AgentState)
        workflow.add_node("analyze", self.analyze_node)
        workflow.add_node("format", self.format_node)
        
        workflow.set_entry_point("analyze")
        workflow.add_edge("analyze", "format")
        workflow.add_edge("format", END)
        
        return workflow.compile()