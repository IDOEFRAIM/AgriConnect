import logging
from typing import TypedDict, Dict, Any, Optional
from langgraph.graph import StateGraph, END
from langchain_core.messages import HumanMessage, SystemMessage
from langchain_community.chat_models import ChatOllama

# --- IMPORTATION DES OUTILS M√âTIERS ---
from tools.health.base_health import HealthDoctorTool

logger = logging.getLogger("Agent.HealthSahel")

# ==============================================================================
# 1. D√âFINITION DE L'√âTAT (STATE)
# ==============================================================================
class AgentState(TypedDict):
    user_query: str
    culture_config: Dict[str, Any]
    diagnosis_raw: Optional[Dict[str, Any]]
    technical_advice_text: str
    final_response: str
    status: str

# ==============================================================================
# 2. L'AGENT DE SANT√â V√âG√âTALE (DOCTEUR DES PLANTES)
# ==============================================================================
class PlantHealthDoctor:

    def __init__(self,ollama_host: str = "http://localhost:11434",llm_client=None,OLLAMA_MODEL:Optional[str] = "mistral" ):
        self.doctor = HealthDoctorTool() 
        self.model_name = OLLAMA_MODEL
        self.llm_client = self._initialize_llm(OLLAMA_MODEL, llm_client, ollama_host)

    def _initialize_llm(self, model_name, llm_client, ollama_host: str):
        try:
            return llm_client if llm_client else ChatOllama(model=model_name, base_url=ollama_host, temperature=0.1) # adapte la temperature

        except Exception as e:
            logger.error(f"√âchec connexion LLM: {e}")
            return None

    def _identify_symptoms_semantically(self, user_text: str) -> str:
        """
        Traduit les descriptions vagues en mots-cl√©s techniques pour aider l'outil.
        Ex: 'belles fleurs violettes qui tuent mon mil' -> 'WONGO STRIGA'
        """
        if not self.llm_client: return user_text
        
        prompt = (
            "Tu es un phytopathologiste expert au Sahel. Analyse cette description : \n"
            f"'{user_text}'\n\n"
            "T√ÇCHE :\n"
            "Identifie les menaces potentielles m√™me si l'utilisateur ne connait pas le nom.\n"
            "- Si √ßa ressemble au Striga (fleurs violettes, plante parasite, herbe sorci√®re), ajoute 'SUSPICION_WONGO STRIGA'.\n"
            "- Si √ßa parle de trous dans les feuilles ou de vers, ajoute 'CHENILLE LEGIONNAIRE'.\n"
            "- Si les feuilles jaunissent ou s√®chent, ajoute 'SECHERESSE ou MALADIE FONGIQUE'.\n\n"
            "R√©ponds juste avec les mots-cl√©s techniques d√©tect√©s."
        )
        try:
            resp = self.llm_client.invoke([SystemMessage(content=prompt), HumanMessage(content="Analyse les sympt√¥mes.")])
            # On ajoute l'analyse √† la requ√™te originale pour garantir que l'outil attrape les mots-cl√©s
            return f"{user_text} {resp.content.upper()}"
        except Exception as e:
            logger.error(f"Erreur semantic symptom detect: {e}")
            return user_text

    # --- N≈íUD 1 : ANALYSE (LOGIQUE M√âTIER) ---
    def analyze_node(self, state: AgentState) -> AgentState:
        """Utilise le HealthDoctorTool pour identifier la menace."""
        config = state.get("culture_config", {})
        crop_name = config.get("crop_name", "Culture inconnue")
        query = state.get("user_query", "")
        
        # --- ENRICHISSEMENT S√âMANTIQUE ---
        # "Je vois des fleurs violettes" -> L'IA ajoute "WONGO STRIGA" -> L'outil d√©clenche l'alerte
        enhanced_query = self._identify_symptoms_semantically(query)

        # Appel √† l'outil m√©tier import√©
        diag = self.doctor.diagnose_and_prescribe(
            crop=crop_name, 
            user_obs=enhanced_query
        )

        # Construction du rapport technique brut enrichi de supports visuels
        # Le nouvel outil retourne un dict avec 'diagnostique' si trouv√©, sinon 'status': 'Inconnu'
        if "diagnostique" in diag:
            # On ins√®re ici les tags visuels pour aider l'agriculteur √† confirmer le diagnostic
            visual_aid = diag.get("diagramme_aide", "")
            prep_aid = self.doctor.get_biopesticide_tutorial("neem") # Exemple par d√©faut
            
            report = (
                f"PATHOLOGIE D√âTECT√âE : {diag['diagnostique']}\n"
                f"NIVEAU DE RISQUE : {diag.get('niveau_alerte')}\n"
                f"RECETTE BIO : {diag.get('prescription_bio')}\n"
                f"GUIDE DE PR√âPARATION : {prep_aid}\n"
                f"CONSEIL CHIMIQUE : {diag.get('conseil_chimique')}\n"
                f"MESURES PR√âVENTIVES : {diag.get('prevention')}"
            )
            status = "Trouv√©"
        else:
            report = f"ERREUR : {diag.get('message', 'Sympt√¥mes non reconnus.')}"
            status = "Inconnu"

        return {
            **state,
            "diagnosis_raw": diag,
            "technical_advice_text": report,
            "status": status
        }

    # --- N≈íUD 2 : FORMATAGE (LLM) ---
    def format_node(self, state: AgentState) -> AgentState:
        """Rend le diagnostic humain, bienveillant et structur√©."""
        if self.llm_client is None or state["status"] != "Trouv√©":
            return {**state, "final_response": state["technical_advice_text"]}

        system_prompt = (
            "Tu es le **Gu√©risseur des Plantes d'AgriConnect**. Ton but est de sauver la r√©colte ET la sant√© du paysan.\n"
            "Ton ennemi jur√© est 'Le Wongo' (Striga) et l'abus de chimie.\n\n"
            "**TON SERMENT :**\n"
            "'Je ne proposerai jamais un poison si un rem√®de naturel existe.'\n\n"
            "**DIRECTIVES M√âDICALES :**\n"
            "1. **BIO D'ABORD :** Ta premi√®re ordonnance est TOUJOURS locale (Feuilles de Neem, Piment, Cendres, Ail). C'est gratut et sain.\n"
            "2. **CHIMIE EN DERNIER RECOURS :** Si l'attaque est critique, propose la chimie mais avec des **Avertissements de S√©curit√© EXTR√äMES** (Gants, masques).\n"
            "3. **DIAGNOSTIC WONGO :** Si c'est le Striga, dis 'Le probl√®me est dans le sol, pas sur la feuille'. Ordonne l'arrachage imm√©diat avant la floraison.\n\n"
            "**STRUCTURE DE L'ORDONNANCE :**\n"
            "- üîç LE NOM DU MAL : Ce que la plante a attrap√©.\n"
            "- üåø LE REM√àDE DE GRAND-M√àRE (Bio) : La recette exacte.\n"
            "- üß™ LE REM√àDE CHOC (Chimique) : Seulement si n√©cessaire (+ Pr√©cautions).\n"
            "- üõ°Ô∏è LE VACCIN (Pr√©vention) : Comment √©viter que √ßa revienne."
        )

        try:
            msg = self.llm_client.invoke([
                SystemMessage(content=system_prompt),
                HumanMessage(content=f"Rapport Technique :\n{state['technical_advice_text']}")
            ])
            return {**state, "final_response": msg.content, "status": "COMPLETED"}
        except Exception:
            return {**state, "final_response": state["technical_advice_text"], "status": "FALLBACK"}

    # --- CONSTRUCTION DU WORKFLOW ---
    def get_graph(self):
        workflow = StateGraph(AgentState)
        workflow.add_node("analyze", self.analyze_node)
        workflow.add_node("format", self.format_node)
        
        workflow.set_entry_point("analyze")
        workflow.add_edge("analyze", "format")
        workflow.add_edge("format", END)
        
        return workflow.compile()