from langgraph.graph import StateGraph, END
from typing import TypedDict, List, Dict, Any, Optional, Callable
import logging
from datetime import datetime

# Importations LangChain
from langchain_core.messages import HumanMessage, SystemMessage
from langchain_core.runnables import Runnable
from langchain_community.chat_models import ChatOllama # <-- NOUVEAU

# Import du toolkit Agronomie
from Tools.crop.base_crop import CropManagerTool

logger = logging.getLogger("agent.crop_management")

# ==============================================================================
# 1. D√âFINITION DE L'√âTAT (INCHANG√â)
# ==============================================================================
class AgentState(TypedDict):
    """√âtat du Graph pour l'Agent de Gestion des Cultures."""
    zone_id: str
    user_query: str
    culture_config: Dict[str, Any]
    
    technical_advice: Optional[str]
    final_response: str
    status: str

# ==============================================================================
# 2. SERVICE DE GESTION DES CULTURES (MISE √Ä JOUR)
# ==============================================================================
class CropManagementService:
    """
    Service g√©rant le workflow de conseil agronomique.
    Utilise un outil technique et un LLM l√©ger (ChatOllama) pour le formatage.
    """
    # Type de l'argument llm_client est maintenant Runnable (le type de ChatOllama)
    def __init__(self, llm_client: Optional[Runnable] = None): 
        self.name = "CropManagementService"
        self.agronomist = CropManagerTool()
        
        # Le client Ollama doit √™tre pass√© √† l'initialisation
        self.llm_client = llm_client
        if not self.llm_client:
            logger.error("Client ChatOllama non fourni. Le n≈ìud LLM √©chouera.")

    # ----------------------------------------------------------------------
    # Fonctions Utilitaires (INCHANG√âES)
    # ----------------------------------------------------------------------

    def _calculate_days_after_sowing(self, sowing_date_str: str) -> int:
        try:
            s_date = datetime.strptime(sowing_date_str, "%Y-%m-%d")
            today = datetime.now()
            delta = today - s_date
            return max(0, delta.days)
        except Exception:
            return -1

    def analyze_node(self, state: AgentState) -> AgentState:
        """
        N≈ìud 1 : D√©termine la cat√©gorie de la requ√™te et appelle l'outil Agronome.
        (Logique de routage inchang√©e)
        """
        # ... (La logique analyze_node reste la m√™me que pr√©c√©demment, elle produit technical_advice)
        
        query = (state.get("user_query") or "").lower()
        config = state.get("culture_config", {})

        crop_name = config.get("crop_name", "la culture")
        sowing_date = config.get("sowing_date")
        response_parts = []
        
        # Logique de routage (r√©utilis√©e pour la compl√©tude)
        if any(w in query for w in ["semis", "semer", "densit√©", "√©cartement"]):
            advice = self.agronomist.get_seeding_advice(crop_name)
            response_parts.append(advice)
        elif any(w in query for w in ["engrais", "npk", "ur√©e", "fertil"]):
            # ... (logique engrais)
            if not sowing_date:
                response_parts.append(
                    "Pour calculer la date d'engrais, j'ai besoin de votre date de semis (format : YYYY-MM-DD)."
                )
            else:
                das = self._calculate_days_after_sowing(sowing_date)
                if das >= 0:
                    status = self.agronomist.check_fertilizer_status(crop_name, das)
                    response_parts.append(f"üìå Stade de la culture : Jour {das}")
                    response_parts.append(status)
                else:
                    response_parts.append("Date de semis invalide (Format attendu : YYYY-MM-DD).")
        elif any(w in query for w in ["r√©colte", "couper", "fin", "maturit√©"]):
            # ... (logique r√©colte)
            if not sowing_date:
                response_parts.append("Pour estimer la r√©colte, j'ai besoin de votre date de semis.")
            else:
                estimation = self.agronomist.estimate_harvest(crop_name, sowing_date)
                response_parts.append(estimation)
        else:
            response_parts.append(f"üìò Fiche Technique ‚Äì {crop_name}")
            response_parts.append("Je peux vous conseiller sur : Les densit√©s de semis, le calendrier d'engrais et les dates de r√©colte.")
            response_parts.append("Posez-moi une question pr√©cise sur l'un de ces sujets.")

        technical_advice = "\n\n".join(response_parts)

        return {
            **state,
            "technical_advice": technical_advice,
            "status": "ADVICE_GENERATED"
        }


    def llm_formatter_node(self, state: AgentState) -> AgentState:
        """
        N≈ìud 2 : Utilise ChatOllama pour transformer le conseil technique 
        en une r√©ponse conviviale pour l'utilisateur.
        """
        if not self.llm_client:
            raise ValueError("Le client LLM (ChatOllama) n'a pas √©t√© initialis√©.")

        technical_advice = state.get("technical_advice", "Aucun conseil technique g√©n√©r√©.")
        user_query = state.get("user_query", "")
        crop_name = state.get("culture_config", {}).get("crop_name", "votre culture")
        
        logger.info(f"[{self.name}] D√©but du formatage LLM avec ChatOllama pour {crop_name}.")

        # --- D√©finition du Prompt pour le LLM L√©ger ---
        system_prompt = (
            "Tu es un agronome professionnel, amical et facile √† comprendre. "
            "Ta t√¢che est de transformer un conseil technique brut en une r√©ponse naturelle "
            "et utile pour l'agriculteur. Ne donne pas de chiffres qui n'ont pas √©t√© "
            "fournis dans le conseil technique. Mets l'accent sur la clart√© et l'action."
        )
        
        human_prompt = f"""
        **Contexte Agricole (Culture) :** {crop_name}
        **Question initiale de l'agriculteur :** "{user_query}"
        **Conseil Technique Brut (g√©n√©r√© par l'outil) :** ---
        {technical_advice}
        ---
        
        Reformule ce conseil technique brut pour l'agriculteur.
        """

        messages = [
            SystemMessage(content=system_prompt),
            HumanMessage(content=human_prompt)
        ]

        # Appel du client ChatOllama
        try:
            response = self.llm_client.invoke(messages)
            final_response = response.content
        except Exception as e:
            logger.error(f"Erreur lors de l'appel ChatOllama : {e}")
            final_response = f"D√©sol√©, une erreur est survenue lors du formatage du conseil. Conseil brut : {technical_advice}"

        return {
            **state,
            "final_response": final_response,
            "status": "SUCCESS"
        }

    # ----------------------------------------------------------------------
    # 3. WORKFLOW LANGGRAPH (INCHANG√â)
    # ----------------------------------------------------------------------
    def get_graph(self):
        """Construit et compile le Graph de l'Agent."""
        workflow = StateGraph(AgentState)
        
        workflow.add_node("manage_crop", self.analyze_node)       # Outil technique
        workflow.add_node("format_llm_response", self.llm_formatter_node) # LLM l√©ger (post-traitement)
        
        workflow.set_entry_point("manage_crop")
        workflow.add_edge("manage_crop", "format_llm_response")
        workflow.add_edge("format_llm_response", END)
        
        return workflow.compile()
