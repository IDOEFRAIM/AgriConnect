import logging
import json
from datetime import datetime
from typing import TypedDict, Dict, Any, Optional, List

# --- Importations LangGraph & LangChain ---
from langgraph.graph import StateGraph, END
from langchain_core.messages import HumanMessage, SystemMessage
from langchain_community.chat_models import ChatOllama
from tools.meteo.basis_tools import SahelAgriAdvisor, SoilType
from tools.meteo.flood_risk import FloodRiskTool

# Configuration du Logger
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger("SahelAgent.Robust")

# ==============================================================================
# 1. Ã‰TAT DE L'AGENT
# ==============================================================================
class AgentState(TypedDict):
    user_query: str
    weather_data: Dict[str, Any]
    culture_info: Dict[str, Any]
    raw_diagnosis: Optional[Dict[str, Any]]
    flood_risk: Optional[Dict[str, Any]]
    final_response: str
    error_log: List[str]

# ==============================================================================
# 2. L'AGENT VIGILANCE CLIMATIQUE
# ==============================================================================
class ClimateVigilance:
    def __init__(self, model_name="llama3:8b", ollama_host="http://localhost:11434", llm_client=None):
        self.advisor = SahelAgriAdvisor()
        self.flood_tool = FloodRiskTool()
        self.llm_name = model_name
        
        try:
            self.llm = llm_client if llm_client else ChatOllama(
                model=self.llm_name, 
                base_url=ollama_host, 
                temperature=0.2 # LÃ©gÃ¨re crÃ©ativitÃ© pour les conseils
            )
        except Exception as e:
            logger.error(f"âŒ Ã‰chec initialisation Ollama: {e}")
            self.llm = None

    # --- Ã‰TAPE 1: LOGIQUE MÃ‰TIER (Calculs froids) ---
    def validate_and_calculate(self, state: AgentState) -> Dict[str, Any]:
        """Nettoie les donnÃ©es et exÃ©cute les outils agronomiques."""
        logger.info("--- NODE: VALIDATION & CALCULS ---")
        errors = []
        w = state.get("weather_data", {})
        c = state.get("culture_info", {})

        # 1. Validation de prÃ©sence
        required_weather = ["t_min", "t_max", "rh", "precip"]
        for param in required_weather:
            if w.get(param) is None:
                errors.append(f"DonnÃ©e mÃ©tÃ©o manquante : {param}")

        if not c.get("crop_name"):
            errors.append("Nom de la culture manquant")

        if errors:
            return {"error_log": errors}

        try:
            # 2. Conversion sÃ©curisÃ©e et Calcul Agronomique
            diagnosis = self.advisor.get_daily_diagnosis(
                crop_key=c["crop_name"],
                soil=c.get("soil_type", SoilType.STANDARD),
                t_min=float(w["t_min"]),
                t_max=float(w["t_max"]),
                rh=float(w["rh"]),
                precip=float(w["precip"]),
                doy=datetime.now().timetuple().tm_yday,
                lat=float(c.get("lat", 12.37)),
                distance_km=25.0
            )
            
            # 3. Risque Inondation
            location = c.get("location", "ouagadougou")
            lat = float(c.get("lat", 12.37))
            lon = float(c.get("lon", -1.52))
            flood_risk = self.flood_tool.check_flood_risk(location, lat, lon)
            
            return {
                "raw_diagnosis": diagnosis, 
                "flood_risk": flood_risk, 
                "error_log": []
            }

        except Exception as e:
            logger.error(f"ðŸ’¥ Erreur calcul : {e}")
            return {"error_log": [f"Erreur technique : {str(e)}"]}

    # --- Ã‰TAPE 2: SYNTHÃˆSE EXPERTE (Langage chaud) ---
    def generate_expert_response(self, state: AgentState) -> Dict[str, Any]:
        """GÃ©nÃ¨re le conseil final avec un ton adaptÃ© au Sahel."""
        if state.get("error_log"):
            return {"final_response": f"âš ï¸ Impossible de formuler un conseil : {', '.join(state['error_log'])}."}

        diag = state["raw_diagnosis"]
        flood = state["flood_risk"]

        if not self.llm:
            return {"final_response": self._fallback_template(diag, flood)}

        # Prompt optimisÃ© pour le terrain
        system_prompt = (
            "Tu es 'Sentinelle d'AgriConnect', l'expert agricole du Sahel.\n"
            "TON : Respectueux, direct, encourageant. Utilise des images simples.\n"
            "RÃˆGLES :\n"
            "1. PRIORITÃ‰ : Si une inondation est prÃ©vue, l'alerte doit Ãªtre au dÃ©but.\n"
            "2. SOLUTIONS LOCALES : Priorise le compost, le paillage et le ZaÃ¯.\n"
            "3. FORMAT : Utilise des listes Ã  puces et des emojis pour la lisibilitÃ© sur mobile."
        )
        
        human_content = (
            f"Culture : {diag.get('culture')}\n"
            f"Diagnostic : {diag}\n"
            f"Risque Inondation : {flood}\n"
            f"Question Agriculteur : {state['user_query']}"
        )

        try:
            response = self.llm.invoke([
                SystemMessage(content=system_prompt),
                HumanMessage(content=human_content)
            ])
            return {"final_response": response.content}
        except Exception:
            return {"final_response": self._fallback_template(diag, flood)}

    def _fallback_template(self, diag: Dict, flood: Dict) -> str:
        """Rendu textuel si l'IA est hors-ligne."""
        res = "ðŸ“¢ [CONSEIL AUTOMATIQUE]\n"
        if flood.get("risk_level") in ["Ã‰levÃ©", "Critique"]:
            res += f"ðŸš¨ ALERTE INONDATION : {flood['alert_message']}\n"
        
        res += f"âœ… Culture : {diag.get('culture', 'Inconnue')}\n"
        res += f"ðŸ’§ Besoin en eau : {diag.get('besoin_eau_etc_mm')} mm\n"
        res += f"ðŸšœ Conseil : {diag.get('conseil_irrigation', "VÃ©rifiez l'humiditÃ© du sol")}"
        return res

    def build(self):
        workflow = StateGraph(AgentState)
        workflow.add_node("logic", self.validate_and_calculate)
        workflow.add_node("expert", self.generate_expert_response)
        workflow.set_entry_point("logic")
        workflow.add_edge("logic", "expert")
        workflow.add_edge("expert", END)
        return workflow.compile()