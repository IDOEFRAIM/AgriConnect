"""
Celery App â€” Point d'entrÃ©e UNIQUE de l'application Celery.

C'est le SEUL endroit oÃ¹ Celery() est instanciÃ©.
Ne JAMAIS redÃ©finir celery_app ailleurs.

Production Checklist:
  âœ… Configuration externalisÃ©e (celery_config.py)
  âœ… Dead Letter Queues pour les tÃ¢ches Ã©chouÃ©es
  âœ… Rate limiting par tÃ¢che
  âœ… Exponential backoff avec jitter
  âœ… Broker transport robuste (retry, timeout, visibility)
  âœ… Worker signals (startup validation, graceful shutdown)
  âœ… Compression gzip (broker + rÃ©sultats)
  âœ… Task tracking (Flower-compatible)
  âœ… Beat schedule pour les tÃ¢ches pÃ©riodiques
"""

import logging
import os

from celery import Celery
from celery.schedules import crontab
from celery.signals import (
    celeryd_init,
    task_failure,
    task_revoked,
    worker_ready,
    worker_shutting_down,
)

from agriconnect.core.settings import settings
from agriconnect.workers.celery_config import get_celery_config, ENVIRONMENT

logger = logging.getLogger("AgriConnect.celery")


# ===================================================================
# 1. CELERY APP INSTANCE
# ===================================================================

celery_app = Celery(
    "agriconnect",
    broker=settings.celery_broker,
    backend=settings.celery_backend,
)


# ===================================================================
# 2. APPLY CONFIGURATION
# ===================================================================

celery_app.conf.update(get_celery_config())


# ===================================================================
# 3. PERIODIC TASKS (Celery Beat)
# ===================================================================

celery_app.conf.beat_schedule = {
    # â”€â”€ Monitoring mÃ©tÃ©o toutes les 6 heures â”€â”€
    "weather-monitoring-every-6h": {
        "task": "agriconnect.workers.tasks.monitoring.check_weather_alerts",
        "schedule": crontab(hour="*/6", minute=0),
        "options": {
            "queue": "monitoring",
            "expires": 3600,
            "priority": 3,
        },
    },

    # â”€â”€ Nettoyage audio quotidien Ã  3h du matin â”€â”€
    "cleanup-audio-daily-3am": {
        "task": "agriconnect.workers.tasks.maintenance.cleanup_old_audio",
        "schedule": crontab(hour=3, minute=0),
        "options": {
            "queue": "maintenance",
            "expires": 7200,
            "priority": 9,
        },
    },

    # â”€â”€ Nettoyage des rÃ©sultats expirÃ©s (quotidien, 4h) â”€â”€
    "cleanup-expired-results-daily": {
        "task": "agriconnect.workers.tasks.maintenance.cleanup_expired_results",
        "schedule": crontab(hour=4, minute=0),
        "options": {
            "queue": "maintenance",
            "expires": 7200,
            "priority": 9,
        },
    },

    # â”€â”€ Health check du broker (5 min en prod, 15 min sinon) â”€â”€
    "broker-health-check": {
        "task": "agriconnect.workers.tasks.maintenance.broker_health_check",
        "schedule": crontab(minute="*/5") if ENVIRONMENT == "production" else crontab(minute="*/15"),
        "options": {
            "queue": "maintenance",
            "expires": 120,
            "priority": 1,
        },
    },
}


# ===================================================================
# 4. AUTO-DISCOVER TASKS
# ===================================================================

celery_app.autodiscover_tasks([
    "agriconnect.workers.tasks",
])


# ===================================================================
# 5. WORKER SIGNALS (lifecycle hooks)
# ===================================================================

@celeryd_init.connect
def _on_celeryd_init(sender=None, conf=None, **kwargs):
    """AppelÃ© au tout dÃ©but du worker, avant le fork."""
    logger.info(
        "ðŸ”§ Celery worker initializing â€” env=%s broker=%s",
        ENVIRONMENT,
        _mask_url(str(conf.broker_url)) if conf else "?",
    )


@worker_ready.connect
def _on_worker_ready(sender=None, **kwargs):
    """AppelÃ© quand le worker est prÃªt Ã  consommer des tÃ¢ches."""
    logger.info("âœ… Celery worker READY â€” PID=%s env=%s", os.getpid(), ENVIRONMENT)
    try:
        conn = celery_app.connection()
        conn.ensure_connection(max_retries=3, interval_start=0.5)
        conn.close()
        logger.info("âœ… Broker connection verified.")
    except Exception as e:
        logger.critical("âŒ Broker connection FAILED at startup: %s", e)


@worker_shutting_down.connect
def _on_worker_shutdown(sig=None, how=None, exitcode=None, **kwargs):
    """AppelÃ© quand le worker reÃ§oit un signal d'arrÃªt."""
    logger.info(
        "ðŸ›‘ Celery worker shutting down â€” signal=%s method=%s exit=%s",
        sig, how, exitcode,
    )


@task_failure.connect
def _on_task_failure(sender=None, task_id=None, exception=None, **kwargs):
    """AppelÃ© quand une tÃ¢che Ã©choue aprÃ¨s tous les retries."""
    logger.error(
        "ðŸ’€ Task FAILED permanently â€” task=%s id=%s error=%s",
        sender.name if sender else "?", task_id, exception,
    )


@task_revoked.connect
def _on_task_revoked(sender=None, request=None, terminated=None, **kwargs):
    """AppelÃ© quand une tÃ¢che est rÃ©voquÃ©e (annulÃ©e)."""
    task_id = request.id if request else "?"
    logger.warning("ðŸš« Task REVOKED â€” id=%s terminated=%s", task_id, terminated)


# ===================================================================
# 6. HELPERS
# ===================================================================

def _mask_url(url: str) -> str:
    """Masque le mot de passe dans une URL pour les logs."""
    if "@" in url:
        pre, post = url.rsplit("@", 1)
        if ":" in pre:
            scheme_user = pre.rsplit(":", 1)[0]
            return f"{scheme_user}:***@{post}"
    return url


# ===================================================================
# 7. CLI ENTRY POINT
# ===================================================================

if __name__ == "__main__":
    celery_app.start()
