"""
Exemple complet et fonctionnel de la pipeline RAG avec vos vraies classes.
Ce script utilise vos vraies classes Retriever, Embedder, Reranker.
"""

from __future__ import annotations
import asyncio
import json
from typing import Any, Dict, List
from pathlib import Path
import sys

# --- Setup paths ---
PROJECT_ROOT = Path(__file__).resolve().parents[2]
if str(PROJECT_ROOT) not in sys.path:
    sys.path.insert(0, str(PROJECT_ROOT))

# Importer VOS vraies classes
from rag.context2 import (
    AugmentationPipeline,
    AugmentationConfig
)

# TODO: Remplacer par vos vraies classes
# from rag.retriever import YourRetriever
# from rag.embedder import YourEmbedder
# from rag.reranker import YourReranker


# =========================================================================
# DONN√âES DE TEST - Bulletins M√©t√©o Simul√©s
# =========================================================================

SAMPLE_BULLETINS = [
    {
        "id": "BAD25092_p1",
        "source": "bulletins_json/BAD25092.json",
        "text": (
            "Les hauteurs de pluie d√©cadaires enregistr√©es du 11 au 20 septembre 2025 "
            "ont vari√© de 0,0 mm √† Dori √† 121,9 mm √† Bobo-Dioulasso. "
            "Les cumuls saisonniers du 01 avril au 20 septembre 2025 ont fluctu√© entre "
            "374,6 mm √† Korsimoro et 1208,0 mm √† Bama."
        ),
        "meta": {
            "date": "2025-09-20",
            "region": "Burkina Faso",
            "type": "bulletin_agro_decadaire"
        }
    },
    {
        "id": "BAD25092_p2",
        "source": "bulletins_json/BAD25092.json",
        "text": (
            "Les pr√©cipitations ont √©t√© g√©n√©ralement faibles sur l'ensemble du territoire "
            "avec des cumuls inf√©rieurs √† 50 mm dans la plupart des stations. "
            "La situation pluviom√©trique reste d√©ficitaire dans les r√©gions du Sahel et du Nord."
        ),
        "meta": {
            "date": "2025-09-20",
            "region": "Burkina Faso",
            "type": "bulletin_agro_decadaire"
        }
    },
    {
        "id": "PREV_OCT_001",
        "source": "bulletins_json/PREV_OCT.json",
        "text": (
            "Pr√©visions pour octobre 2025: Les mod√®les indiquent une reprise des pluies "
            "sur la partie sud du pays avec des cumuls attendus entre 80 et 150 mm. "
            "Les temp√©ratures maximales devraient se situer entre 32¬∞C et 35¬∞C."
        ),
        "meta": {
            "date": "2025-09-25",
            "region": "Burkina Faso",
            "type": "prevision"
        }
    },
    {
        "id": "TEMP_SEPT_001",
        "source": "bulletins_json/TEMP_SEPT.json",
        "text": (
            "Les temp√©ratures moyennes de septembre 2025 ont oscill√© entre 25¬∞C et 30¬∞C. "
            "Les nuits ont √©t√© plus fra√Æches avec des minimales autour de 22¬∞C. "
            "Aucune vague de chaleur n'a √©t√© observ√©e durant ce mois."
        ),
        "meta": {
            "date": "2025-09-30",
            "region": "Burkina Faso",
            "type": "observation"
        }
    },
    {
        "id": "CUMUL_AVRIL_001",
        "source": "bulletins_json/CUMUL_SAISON.json",
        "text": (
            "Bilan pluviom√©trique saisonnier (avril-septembre 2025): "
            "Les cumuls varient de 374,6 mm (d√©ficitaire) √† 1208,0 mm (exc√©dentaire). "
            "La moyenne nationale s'√©tablit √† 687 mm, l√©g√®rement en dessous de la normale."
        ),
        "meta": {
            "date": "2025-09-30",
            "region": "Burkina Faso",
            "type": "bilan"
        }
    },
    {
        "id": "VENT_SEPT_001",
        "source": "bulletins_json/VENT_SEPT.json",
        "text": (
            "Les vents de septembre ont souffl√© principalement du secteur sud-ouest "
            "avec une vitesse moyenne de 15 km/h. Des rafales jusqu'√† 45 km/h ont √©t√© "
            "enregistr√©es lors des passages pluvieux."
        ),
        "meta": {
            "date": "2025-09-30",
            "region": "Burkina Faso",
            "type": "observation"
        }
    }
]


# =========================================================================
# FONCTION PRINCIPALE
# =========================================================================

async def main():
    print("=" * 70)
    print("EXEMPLE COMPLET FONCTIONNEL - PIPELINE RAG V2")
    print("=" * 70)
    
    # 1. Initialiser VOS composants
    print("\nüì¶ Initialisation des composants...")
    
    # TODO: Remplacer par vos vraies classes
    # embedder = YourEmbedder(model_name="your-model")
    # retriever = YourRetriever(documents=SAMPLE_BULLETINS, embedder=embedder)
    # reranker = YourReranker(model_name="your-reranker")
    
    # Pour l'instant, on garde les mocks pour que √ßa compile
    from rag.utils.embedder import Embedder,EmbedderConfig
    from rag.utils.retriever import Retriever,RetrieverConfig  
    from rag.utils.indexer_init import MilvusIndexer
    from rag.utils.reRank import Reranker
    from rag.utils.crossEncoder import CrossEncoder

    collection_name = "sample_collection"
    embedder = Embedder()
    indexer = MilvusIndexer()
    retriever = Retriever(indexer=indexer, embedder=embedder, collection=collection_name)
    reranker = Reranker(cross_encoder=CrossEncoder)
    
    print(f"  ‚úì Embedder: initialis√©")
    print(f"  ‚úì Retriever: {len(SAMPLE_BULLETINS)} documents index√©s")
    print(f"  ‚úì Reranker: activ√©")
    
    # 2. Configuration optimale
    print("\n‚öôÔ∏è  Configuration de la pipeline...")
    config = AugmentationConfig(
        # Retrieval
        top_k=10,
        rerank_top_n=5,
        max_snippets_per_doc=2,
        snippet_max_tokens=150,
        min_snippet_score=0.1,
        
        # Scoring
        retrieval_weight=0.3,
        rerank_weight=0.5,
        semantic_weight=0.2,
        diversity_penalty=0.1,
        
        # Performance
        concurrency=4,
        batch_size=16,
        enable_caching=True,
        cache_ttl_s=3600.0,
        
        # Quality
        enable_deduplication=True,
        dedup_threshold=0.85,
        enable_quality_filter=True,
        min_text_length=20,
        
        # Cross-encoder
        use_cross_encoder=True,
        
        # Timeouts
        timeout_s=10.0,
        retrieval_timeout_s=3.0,
        rerank_timeout_s=2.0,
        encode_timeout_s=2.0,
        
        # Monitoring
        enable_metrics=True,
        log_slow_queries=True,
        slow_query_threshold_s=2.0
    )
    
    pipeline = AugmentationPipeline(
        retriever=retriever,
        encoder=CrossEncoder,
        reranker=reranker,
        cfg=config
    )
    
    print("  ‚úì Pipeline configur√©e avec m√©triques activ√©es")
    
    # 3. Test avec requ√™tes vari√©es
    test_queries = [
        "Quelle est la tendance pluviom√©trique pour la p√©riode 11-20 septembre 2025 ?",
        "Quelles sont les pr√©visions de pluie pour octobre 2025 ?",
        "Quelle est la temp√©rature moyenne en septembre 2025 ?",
        "Quel est le cumul de pr√©cipitations depuis avril 2025 ?",
        "Quelle est la situation des vents en septembre ?",
    ]
    
    print(f"\nüîç Test avec {len(test_queries)} requ√™tes...\n")
    
    for i, query in enumerate(test_queries, 1):
        print(f"\n{'=' * 70}")
        print(f"REQU√äTE {i}/{len(test_queries)}")
        print(f"{'=' * 70}")
        print(f"‚ùì {query}\n")
        
        # Ex√©cuter la pipeline
        response = await pipeline.augment(query)
        result = response.to_dict()
        
        # Afficher r√©sultats
        print(f"üìä R√âSULTATS:")
        print(f"  ‚úì Snippets retourn√©s: {len(result['context']['snippets'])}")
        print(f"  ‚úì Total tokens: {result['context']['total_tokens']}")
        print(f"  ‚úì Temps total: {result['diagnostics']['timings']['total_time_s']:.3f}s")
        
        # Cache stats avec affichage correct
        cache_info = result['diagnostics']['cache']
        print(f"  ‚úì Cache: {cache_info.get('hit_rate_display', 'N/A')} "
              f"({cache_info['cache_hits']} hits, {cache_info['cache_misses']} misses)")
        
        # Top snippets
        if result['context']['snippets']:
            print(f"\nüìÑ TOP SNIPPETS:")
            for j, snippet in enumerate(result['context']['snippets'][:3], 1):
                print(f"\n  {j}. Doc: {snippet['doc_id']}")
                print(f"     Score: {snippet.get('rerank_score', 0.0):.3f}")
                print(f"     Texte: {snippet['text'][:120]}...")
        else:
            print("\n  ‚ö†Ô∏è  Aucun snippet trouv√©")
        
        # Diagnostics d√©taill√©s
        if result['diagnostics'].get('steps'):
            print(f"\n‚öôÔ∏è  DIAGNOSTICS D√âTAILL√âS:")
            for step_name, step_data in result['diagnostics']['steps'].items():
                count = step_data.get('count', 'N/A')
                time_s = step_data.get('time_s', 0)
                print(f"  - {step_name}: {count} items en {time_s:.3f}s")
        
        # Warnings/Errors
        if result['diagnostics'].get('warnings'):
            print(f"\n  ‚ö†Ô∏è  Warnings: {len(result['diagnostics']['warnings'])}")
        
        if result['diagnostics'].get('errors'):
            print(f"\n  ‚úó Errors: {len(result['diagnostics']['errors'])}")
    
    # 4. M√âTRIQUES GLOBALES (MAINTENANT DISPONIBLE!)
    print(f"\n\n{'=' * 70}")
    print("üìà M√âTRIQUES GLOBALES DE LA PIPELINE")
    print(f"{'=' * 70}")
    
    metrics = pipeline.get_metrics()
    
    print(f"\nüéØ Performance:")
    print(f"  Total queries: {metrics['total_queries']}")
    print(f"  Success rate: {metrics['success_rate'] * 100:.1f}%")
    print(f"  Avg latency: {metrics['avg_latency_s']:.3f}s")
    print(f"  P95 latency: {metrics['p95_latency_s']:.3f}s")
    print(f"  P99 latency: {metrics['p99_latency_s']:.3f}s")
    print(f"  Min latency: {metrics['min_latency_s']:.3f}s")
    print(f"  Max latency: {metrics['max_latency_s']:.3f}s")
    
    print(f"\nüíæ Cache:")
    cache_metrics = metrics['cache']
    print(f"  Size: {cache_metrics['cache_size']} entries")
    print(f"  Total requests: {cache_metrics['total_requests']}")
    print(f"  Hit rate: {cache_metrics['hit_rate_pct']}")
    print(f"  Hits: {cache_metrics['hits']}")
    print(f"  Misses: {cache_metrics['misses']}")
    
    print(f"\n‚è±Ô∏è  Uptime: {metrics['uptime_s']:.1f}s")
    
    # 5. Sauvegarder exemple complet
    print(f"\n\n{'=' * 70}")
    print("üíæ SAUVEGARDE EXEMPLE COMPLET")
    print(f"{'=' * 70}\n")
    
    final_response = await pipeline.augment(test_queries[0])
    final_json = final_response.to_dict()
    
    output_file = "example_augmented_response.json"
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(final_json, f, indent=2, ensure_ascii=False)
    
    print(f"‚úÖ R√©ponse compl√®te sauvegard√©e dans: {output_file}")
    
    # 6. Test cache warming (relancer m√™me query)
    print(f"\n\n{'=' * 70}")
    print("üî• TEST CACHE WARMING")
    print(f"{'=' * 70}\n")
    
    print("Relance de la premi√®re query pour tester le cache...")
    cache_before = metrics['cache']['hits']
    
    response2 = await pipeline.augment(test_queries[0])
    
    metrics_after = pipeline.get_metrics()
    cache_after = metrics_after['cache']['hits']
    
    print(f"\n‚úì Cache hits avant: {cache_before}")
    print(f"‚úì Cache hits apr√®s: {cache_after}")
    print(f"‚úì Nouveaux hits: {cache_after - cache_before}")
    print(f"‚úì Hit rate global: {metrics_after['cache']['hit_rate_pct']}")
    
    print(f"\n{'=' * 70}")
    print("‚ú® D√âMONSTRATION COMPL√àTE TERMIN√âE")
    print(f"{'=' * 70}\n")
    
    print("üìù R√âSUM√â DES AM√âLIORATIONS:")
    print("  ‚úì Cache avec cl√©s normalis√©es (Unicode, espaces, etc.)")
    print("  ‚úì Hit rate calcul√© correctement")
    print("  ‚úì M√©triques de performance (latences, percentiles)")
    print("  ‚úì Sauvegarde atomique du cache")
    print("  ‚úì Utilisation de time.perf_counter() pour pr√©cision")
    print("  ‚úì Stats d√©taill√©es par requ√™te et globales")


# =========================================================================
# Point d'entr√©e
# =========================================================================

if __name__ == "__main__":
    asyncio.run(main())